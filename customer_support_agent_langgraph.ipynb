{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building an Intelligent Customer Support Agent with LangGraph\n",
    "\n",
    "## Key Components\n",
    "1. **State Management**: Using TypedDict to define and manage the state of each customer interaction.\n",
    "2. **Query Categorization**: Classifying customer queries into Technical, Billing, or General categories.\n",
    "3. **Sentiment Analysis**: Determining the emotional tone of customer queries.\n",
    "4. **Response Generation**: Creating appropriate responses based on the query category and sentiment.\n",
    "5. **Escalation Mechanism**: Automatically escalating queries with negative sentiment to human agents.\n",
    "6. **Workflow Graph**: Utilizing LangGraph to create a flexible and extensible workflow.\n",
    "\n",
    "## Method Details\n",
    "1. **Initialization**: Set up the environment and import necessary libraries.\n",
    "2. **State Definition**: Create a structure to hold query information, category, sentiment, and response.\n",
    "3. **Node Functions**: Implement separate functions for categorization, sentiment analysis, and response generation.\n",
    "4. **Graph Construction**: Use StateGraph to define the workflow, adding nodes and edges to represent the support process.\n",
    "5. **Conditional Routing**: Implement logic to route queries based on their category and sentiment.\n",
    "6. **Workflow Compilation**: Compile the graph into an executable application.\n",
    "7. **Execution**: Process customer queries through the workflow and retrieve results.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import necessary libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from typing import Dict, TypedDict\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "from IPython.display import display, Image\n",
    "from langchain_core.runnables.graph import MermaidDrawMethod\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load environment variables and set OpenAI API key\n",
    "load_dotenv()\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "We define a `State` class to hold the query, category, sentiment, and response for each customer interaction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class State(TypedDict):\n",
    "    query: str\n",
    "    category: str\n",
    "    sentiment: str\n",
    "    response: str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Node Functions\n",
    "\n",
    "These functions represent the different stages of processing a customer query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorize(state: State) -> State:\n",
    "    \"\"\"Categorize the customer query into Technical, Billing, or General.\"\"\"\n",
    "    prompt = ChatPromptTemplate.from_template(\n",
    "        \"Categorize the following customer query into one of these categories: \"\n",
    "        \"Technical, Billing, General. Query: {query}\"\n",
    "    )\n",
    "    chain = prompt | ChatOpenAI(temperature=0)\n",
    "    category = chain.invoke({\"query\": state[\"query\"]}).content\n",
    "    return {\"category\": category}\n",
    "\n",
    "def analyze_sentiment(state: State) -> State:\n",
    "    \"\"\"Analyze the sentiment of the customer query as Positive, Neutral, or Negative.\"\"\"\n",
    "    prompt = ChatPromptTemplate.from_template(\n",
    "        \"Analyze the sentiment of the following customer query. \"\n",
    "        \"Respond with either 'Positive', 'Neutral', or 'Negative'. Query: {query}\"\n",
    "    )\n",
    "    chain = prompt | ChatOpenAI(temperature=0)\n",
    "    sentiment = chain.invoke({\"query\": state[\"query\"]}).content\n",
    "    return {\"sentiment\": sentiment}\n",
    "\n",
    "def handle_technical(state: State) -> State:\n",
    "    \"\"\"Provide a technical support response to the query.\"\"\"\n",
    "    prompt = ChatPromptTemplate.from_template(\n",
    "        \"Provide a technical support response to the following query: {query}\"\n",
    "    )\n",
    "    chain = prompt | ChatOpenAI(temperature=0)\n",
    "    response = chain.invoke({\"query\": state[\"query\"]}).content\n",
    "    return {\"response\": response}\n",
    "\n",
    "def handle_billing(state: State) -> State:\n",
    "    \"\"\"Provide a billing support response to the query.\"\"\"\n",
    "    prompt = ChatPromptTemplate.from_template(\n",
    "        \"Provide a billing support response to the following query: {query}\"\n",
    "    )\n",
    "    chain = prompt | ChatOpenAI(temperature=0)\n",
    "    response = chain.invoke({\"query\": state[\"query\"]}).content\n",
    "    return {\"response\": response}\n",
    "\n",
    "def handle_general(state: State) -> State:\n",
    "    \"\"\"Provide a general support response to the query.\"\"\"\n",
    "    prompt = ChatPromptTemplate.from_template(\n",
    "        \"Provide a general support response to the following query: {query}\"\n",
    "    )\n",
    "    chain = prompt | ChatOpenAI(temperature=0)\n",
    "    response = chain.invoke({\"query\": state[\"query\"]}).content\n",
    "    return {\"response\": response}\n",
    "\n",
    "def escalate(state: State) -> State:\n",
    "    \"\"\"Escalate the query to a human agent due to negative sentiment.\"\"\"\n",
    "    return {\"response\": \"This query has been escalated to a human agent due to its negative sentiment.\"}\n",
    "\n",
    "def route_query(state: State) -> str:\n",
    "    \"\"\"Route the query based on its sentiment and category.\"\"\"\n",
    "    if state[\"sentiment\"] == \"Negative\":\n",
    "        return \"escalate\"\n",
    "    elif state[\"category\"] == \"Technical\":\n",
    "        return \"handle_technical\"\n",
    "    elif state[\"category\"] == \"Billing\":\n",
    "        return \"handle_billing\"\n",
    "    else:\n",
    "        return \"handle_general\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating and Configuring the Graph\n",
    "\n",
    "Here we set up the LangGraph, defining nodes and edges to create our customer support workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the graph\n",
    "workflow = StateGraph(State)\n",
    "\n",
    "# Add nodes\n",
    "workflow.add_node(\"categorize\", categorize)\n",
    "workflow.add_node(\"analyze_sentiment\", analyze_sentiment)\n",
    "workflow.add_node(\"handle_technical\", handle_technical)\n",
    "workflow.add_node(\"handle_billing\", handle_billing)\n",
    "workflow.add_node(\"handle_general\", handle_general)\n",
    "workflow.add_node(\"escalate\", escalate)\n",
    "\n",
    "# Add edges\n",
    "workflow.add_edge(\"categorize\", \"analyze_sentiment\")\n",
    "workflow.add_conditional_edges(\n",
    "    \"analyze_sentiment\",\n",
    "    route_query,\n",
    "    {\n",
    "        \"handle_technical\": \"handle_technical\",\n",
    "        \"handle_billing\": \"handle_billing\",\n",
    "        \"handle_general\": \"handle_general\",\n",
    "        \"escalate\": \"escalate\"\n",
    "    }\n",
    ")\n",
    "workflow.add_edge(\"handle_technical\", END)\n",
    "workflow.add_edge(\"handle_billing\", END)\n",
    "workflow.add_edge(\"handle_general\", END)\n",
    "workflow.add_edge(\"escalate\", END)\n",
    "\n",
    "# Set entry point\n",
    "workflow.set_entry_point(\"categorize\")\n",
    "\n",
    "# Compile the graph\n",
    "app = workflow.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing the Graph\n",
    "\n",
    "This cell generates and displays a visual representation of our LangGraph workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(\n",
    "    Image(\n",
    "        app.get_graph().draw_mermaid_png(\n",
    "            draw_method=MermaidDrawMethod.API,\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running Customer Support Function\n",
    "\n",
    "This function processes a customer query through our LangGraph workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_customer_support(query: str) -> Dict[str, str]:\n",
    "    \"\"\"Process a customer query through the LangGraph workflow.\n",
    "    \n",
    "    Args:\n",
    "        query (str): The customer's query\n",
    "        \n",
    "    Returns:\n",
    "        Dict[str, str]: A dictionary containing the query's category, sentiment, and response\n",
    "    \"\"\"\n",
    "    results = app.invoke({\"query\": query})\n",
    "    return {\n",
    "        \"category\": results[\"category\"],\n",
    "        \"sentiment\": results[\"sentiment\"],\n",
    "        \"response\": results[\"response\"]\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the Customer Support Agent\n",
    "\n",
    "Let's test our customer support agent with a sample queries for each kind of query type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# escalate\n",
    "\n",
    "query = \"My internet connection keeps dropping. Can you help?\"\n",
    "result = run_customer_support(query)\n",
    "print(f\"Query: {query}\")\n",
    "print(f\"Category: {result['category']}\")\n",
    "print(f\"Sentiment: {result['sentiment']}\")\n",
    "print(f\"Response: {result['response']}\")\n",
    "print(\"\\n\")\n",
    "\n",
    "# handle_technical\n",
    "\n",
    "query = \"I need help talking to chatGPT\"\n",
    "result = run_customer_support(query)\n",
    "print(f\"Query: {query}\")\n",
    "print(f\"Category: {result['category']}\")\n",
    "print(f\"Sentiment: {result['sentiment']}\")\n",
    "print(f\"Response: {result['response']}\")\n",
    "print(\"\\n\")\n",
    "\n",
    "# handle_billing\n",
    "\n",
    "query = \"where can i find my receipt?\"\n",
    "result = run_customer_support(query)\n",
    "print(f\"Query: {query}\")\n",
    "print(f\"Category: {result['category']}\")\n",
    "print(f\"Sentiment: {result['sentiment']}\")\n",
    "print(f\"Response: {result['response']}\")\n",
    "print(\"\\n\")\n",
    "\n",
    "# handle_general\n",
    "\n",
    "query = \"What are your business hours?\"\n",
    "result = run_customer_support(query)\n",
    "print(f\"Query: {query}\")\n",
    "print(f\"Category: {result['category']}\")\n",
    "print(f\"Sentiment: {result['sentiment']}\")\n",
    "print(f\"Response: {result['response']}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
